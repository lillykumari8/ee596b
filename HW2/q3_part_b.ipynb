{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "import timeit, time\n",
    "import load_cifar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = '/home/lkumari/data/cifar-10-batches-py/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Hyperparameter</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "lr = 0.01\n",
    "num_classes = 10\n",
    "num_batches = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Placeholder</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "Y = tf.placeholder(tf.int32, [None, 10])\n",
    "\n",
    "\n",
    "mean = 0.0\n",
    "stddev = 0.1\n",
    "\n",
    "def initialize_weight(shape, mean, stddev):\n",
    "    W = tf.truncated_normal(shape=shape, mean = mean, stddev = stddev)\n",
    "    return tf.Variable(W)\n",
    "\n",
    "\n",
    "\n",
    "weights = {\n",
    "    'W_conv1': tf.Variable(initialize_weight([5,5,3,6], mean, stddev),name='W_conv1'),\n",
    "    'W_conv2': tf.Variable(initialize_weight([5,5,6,16], mean, stddev),name='W_conv2'),\n",
    "    'W_fc1': tf.Variable(initialize_weight([5*5*16,120], mean, stddev),name='W_fc1'),\n",
    "    'W_fc2': tf.Variable(initialize_weight([120,84], mean, stddev),name='W_fc2'),\n",
    "    'W_out': tf.Variable(initialize_weight([84,num_classes], mean, stddev),name='W_out')\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b_conv1': tf.Variable(tf.zeros(shape=[6]),name='b_conv1'),\n",
    "    'b_conv2': tf.Variable(tf.zeros(shape=[16]),name='b_conv2'),\n",
    "    'b_fc1': tf.Variable(tf.zeros(shape=[120]),name='b_fc1'),\n",
    "    'b_fc2': tf.Variable(tf.zeros(shape=[84]),name='b_fc2'),\n",
    "    'b_out': tf.Variable(tf.zeros(shape=[num_classes]),name='b_out')\n",
    "}\n",
    "    \n",
    "def batch_norm(input):\n",
    "    return tf.contrib.layers.batch_norm(input, decay=0.9, epsilon=1e-3, center=True, scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>LeNet-5</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def LeNet(x):\n",
    "    conv1 = tf.nn.conv2d(x, weights['W_conv1'], strides=[1,1,1,1], padding='VALID') + biases['b_conv1']\n",
    "    conv1 = tf.nn.relu(batch_norm(conv1))\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "    \n",
    "    conv2 = tf.nn.conv2d(conv1, weights['W_conv2'], strides=[1,1,1,1], padding='VALID') + biases['b_conv2']\n",
    "    conv2 = tf.nn.relu(batch_norm(conv2))\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "    \n",
    "    fc_input = tf.contrib.layers.flatten(conv2)\n",
    "    \n",
    "    fc1 = tf.matmul(fc_input, weights['W_fc1']) + biases['b_fc1']\n",
    "    fc1 = tf.nn.relu(batch_norm(fc1))\n",
    "    \n",
    "    fc2 = tf.matmul(fc1, weights['W_fc2']) + biases['b_fc2']\n",
    "    fc2 = tf.nn.relu(batch_norm(fc2))\n",
    "    \n",
    "    out = tf.matmul(fc2, weights['W_out']) + biases['b_out']\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Cost and Optimization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n"
     ]
    }
   ],
   "source": [
    "#predicted labels\n",
    "logits = LeNet(X)\n",
    "\n",
    "#define loss\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,labels=Y),name='loss')\n",
    "#define optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "#compare the predicted labels with true labels\n",
    "correct_pred = tf.equal(tf.argmax(logits,1),tf.argmax(Y,1))\n",
    "\n",
    "#compute the accuracy by taking average\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32),name='accuracy')\n",
    "\n",
    "#Initialize the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Training, validation and testing</h1>\n",
    "<h2>Train your model only 10 epochs.</h2>\n",
    "<h2>1.Print out validation accuracy after each training epoch</h2>\n",
    "<h2>2.Print out training time for each training epoch</h2>\n",
    "<h2>3.Print out testing accuracy</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: training loss = 1.578251838684082, training_time = 4.613215684890747, val_accuracy = 0.5217999815940857, test_accuracy = 0.5181999802589417\n",
      "Epoch 1: training loss = 1.2737643718719482, training_time = 4.29104208946228, val_accuracy = 0.5483999848365784, test_accuracy = 0.5483999848365784\n",
      "Epoch 2: training loss = 1.0994131565093994, training_time = 4.266815423965454, val_accuracy = 0.5633999705314636, test_accuracy = 0.5670999884605408\n",
      "Epoch 3: training loss = 1.0075470209121704, training_time = 4.218254566192627, val_accuracy = 0.579200029373169, test_accuracy = 0.5782999992370605\n",
      "Epoch 4: training loss = 0.8623148798942566, training_time = 4.209357261657715, val_accuracy = 0.5785999894142151, test_accuracy = 0.5795000195503235\n",
      "Epoch 5: training loss = 0.6508873701095581, training_time = 4.241961479187012, val_accuracy = 0.6019999980926514, test_accuracy = 0.6044999957084656\n",
      "Epoch 6: training loss = 0.5946696996688843, training_time = 4.2045042514801025, val_accuracy = 0.6055999994277954, test_accuracy = 0.6050000190734863\n",
      "Epoch 7: training loss = 0.5356210470199585, training_time = 4.212867736816406, val_accuracy = 0.6069999933242798, test_accuracy = 0.6031000018119812\n",
      "Epoch 8: training loss = 0.48652535676956177, training_time = 4.2175538539886475, val_accuracy = 0.6039999723434448, test_accuracy = 0.6018999814987183\n",
      "Epoch 9: training loss = 0.43653783202171326, training_time = 4.244187593460083, val_accuracy = 0.6011999845504761, test_accuracy = 0.6019999980926514\n"
     ]
    }
   ],
   "source": [
    "val_accuracy = []\n",
    "test_accuracy = []\n",
    "time_taken = []\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for ep in range(EPOCHS):\n",
    "        start_time = time.time()\n",
    "        for batch_num in range(1, num_batches+1):\n",
    "            for batch_features, batch_labels in load_cifar.load_preprocessed_training_batch(batch_num, BATCH_SIZE):\n",
    "                bat_features = load_cifar.features_reshape(batch_features)\n",
    "                train_loss, acc, _ = sess.run(fetches=[loss, accuracy, train_op], feed_dict={X: bat_features, Y: batch_labels})\n",
    "        end_time = time.time()\n",
    "        time_s = end_time - start_time\n",
    "        \n",
    "        val_features, val_labels = load_cifar.load_preprocessed_validation_batch()\n",
    "        val_features = load_cifar.features_reshape(val_features)\n",
    "        val_acc = sess.run(fetches=[accuracy], feed_dict={X:val_features, Y:val_labels})\n",
    "\n",
    "        test_features, test_labels = load_cifar.load_preprocessed_test()\n",
    "        test_features = load_cifar.features_reshape(test_features)\n",
    "        test_acc = sess.run(fetches=[accuracy], feed_dict={X:test_features, Y:test_labels})\n",
    "        \n",
    "        val_accuracy.append(val_acc[0])\n",
    "        test_accuracy.append(test_acc[0])\n",
    "        time_taken.append(time_s)\n",
    "                \n",
    "        print(\"Epoch {}: training loss = {}, training_time = {}, val_accuracy = {}, test_accuracy = {}\".format(\n",
    "        ep, train_loss, time_s, val_acc[0], test_acc[0]))\n",
    "\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
